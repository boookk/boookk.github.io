[ { "title": "Transaction", "url": "/posts/Transaction/", "categories": "MSA", "tags": "msa, spring", "date": "2022-04-20 23:00:00 +0900", "snippet": "💨 Monoliths ↔ MSA 전환 Application Logic layer부터 순차적으로 분해 Router 구축 Monoliths가 router를 통해 요청 받게 하기 API로 통신 가능한 작은 규모의 서비스를 분리하여 microservice 1개 구축 구축된 서비스만 proxy 전환 DB 또는 schema 분리 분리된 서비스를 위한 Data Migration 검증 및 확장🏃 데이터 이관 전략 Downtime 갖고 한 번에 ETL (Extract, Transform, Load) 구DB와 새 DB 둘 다 사용하지만, Monoliths에서는 ReadOnly CDC를 이용하여 변경되는 데이터만 새 DB에 반영 오늘날에는 AWS Snowball 등 클라우드 서비스를 통해 데이터베이스 마이그레이션 간편화🧐 Change Data Capture DB의 로그 파일을 분석해 변경된 데이터를 추출하는 기술🏗 MSA에서의 DB 설계🙂 이상 분리된 서비스 당 독립된 데이터베이스 소유 다른 서비스에서 관리하는 데이터는 API를 통해서만 참조🙃 현실 서로 다른 서비스가 같은 데이터를 동시에 CUD 하지 않도록 설계 반드시 물리적으로 데이터베이스 분리 불필요🌉 분산 DB 설계 서비스 당 1개 DB 서비스 당 1개 DB + 필요한 DB Link View 하나의 DB를 하나의 서비스만 CUD 권한을 가지고, 나머지는 ReadOnly 1개 DB 내에서 TableSpace만 구분 1개 DB 내에서 Schema만 구분 공통 서비스에 대한 Shared Data 구축❓ Transaction 데이터베이스의 상태를 변경시키기 위해 수행하는 작업 단위 Create, Delete, Update, Insert 모음 동시성 제어와 Recovery 기본 단위❓ SAGA 분산 트랜잭션 시나리오에서 마이크로 서비스에서 데이터 일관성을 관리하는 방법Orchestration SAGA 중앙 집중식 컨트롤러가 각 서비스에게 실행할 트랜잭션 알려주는 방법🧐 하나의 서비스에서라도 트랜잭션이 실패한다면? 성공한 트랜잭션 rollback 로직을 수행하여 일관성 유지Choreography 중앙 집중식 제어 없이 Message Queue를 이용하여 비동기로 트랜잭션 로직 요청 서비스 간 event Publish하고 Subscribe 시스템 복잡도 증가🧐 하나의 서비스에서 트랜잭션이 실패한다면? 약속된 Fallback을 수행하거나, RetryCQRS Command and Query Responsibility Segregation Command와 Query의 책임을 분리하는 패턴수준 1. 서비스 수준에서 CUD와 R 역할 구분수준 2. read-replica 사용수준 3. CUD DB와 R DB를 분리하고 동기화 보통 RDB와 NoSQL 기반의 DB를 사용하는 경우 Event Broker를 통해 변경사항을 동기화수준 4. EventSourcinghttps://docs.microsoft.com/ko-kr/azure/architecture/patterns/event-sourcing 모든 트랜잭션을 Event로 streaming Event Broker 없이 EventStream 저장용 Data Storage 관리 데이터의 상태 변경 이력 관리 가능출처 SAGA EventSourcing" }, { "title": "Netflixed", "url": "/posts/Netflixed/", "categories": "MSA", "tags": "msa, netflix, cloud", "date": "2022-04-20 23:00:00 +0900", "snippet": "🧐 Netflixed 미국 실리콘밸리에서 기존 비즈니스 모델이 붕괴되었을 때를 일컫는 말✨ Netflix OpenSource Software 기존 Legacy 시스템을 클라우드 환경의 MSA로 전환하기 위해 사용한 기술을 공개한 것🏃 Netflix는 MSA의 선구자🧶 Eureka Client와 Application server 사이에서 로드 밸런싱 및 장애 조치를 위해 AWS 클라우드에서 주로 사용되는 RESTful 서비스 클라우드 기반의 MSA 서비스의 IP와 port는 일정하지 않고 지속적으로 변화 Eureka는 클라우드 환경에서 연결 정보 등록 및 해지를 도와주는 역할 Eureka Server와 Eureka Client로 구성🧐 Eureka Client 서비스마다 Eureka client 설치 Spring에서 annotation만 추가하면 사용 가능 Eureka Client는 스스로 Eureka server에 등록 연결 정보 Meta Data를 Eureka 서버에 등록🧐 Eureka Server Eureka server가 Registry에 Eureak client 등록 Registry에 Eureka client의 Meta data 등록 Client의 상태 확인🧐 Registry 서비스의 연결 정보를 등록하는 것🧐 Discovery 다른 서비스의 정보를 찾는 것👮 Zuul API Gateway 구현체 라우팅 역할 Endpoint 관리 통합 Reverse proxy 인증 및 접근 제어💊 Hystrix 분산 서비스 간의 상호 작용을 제어하는 데 도움을 주는 라이브러리 종속성으로 인한 지연 및 장애로부터 보호하고 제어하는 기능 실패 서비스 액세스 격리 빠르게 실패하고 빠르게 복구 가능 실시간에 가까운 모니터링, 경고 및 운영 제어 가능출처 Netflix OSS" }, { "title": "Micro Service Architecture", "url": "/posts/Micro-Service-Architecture/", "categories": "MSA", "tags": "msa, spring", "date": "2022-04-19 23:00:00 +0900", "snippet": "❓ Monoliths 전통적인 시스템 구조로 하나의 단위로 개발하는 단일 서비스 개발 방식📍 Monolith 단점 긴 빌드 시간 및 테스트 시간 특정 개발 언어, DB에 종속 선택적으로 확장 불가능 서비스 간 높은 의존성❓ Software 모듈화 큰 문제를 해결하기 위해 작은 단위로 나누어 개발하는 방법 마이크로 서비스를 만들기 위한 첫 과정 서비스 기능의 확장, 수정, 테스트, 재사용 편리💡 모듈 설계 조건 모듈마다 다른 모듈과 구분되는 독립적인 기능 수행 독립적인 컴파일 가능 한 모듈에서 다른 모듈 호출 가능🔎 모듈화의 특징캡슐화 모듈 내 동작 방식, 데이터 구조를 다른 모듈에게 은폐추상화 다른 모듈은 추상화 된 기능으로만 모듈에 접근독립성 서로 다른 모듈끼리 낮은 결합도 한 모듈 내부에서는 높은 응집도💡 분산 컴퓨팅 환경의 소프트웨어 요구 조건 개발 언어에 상관없이 동일한 서비스 동작 컴포넌트가 특정 플랫폼에 비종속적 서비스 유지보수 용이❓ SOA Service Oriented Architecture 컴포넌트를 모아 비즈니스적으로 의미 있고 완결적인 서비스 단위로 모듈화하는 방법론🔎 SOA 특징 특정 플랫폼에 비종속 서비스 간 낮은 결합도 서비스 위치 투명성 하나의 DB를 공유하기 때문에 독립적으로 사용 불가능 MSA와 비슷한 개념이지만, 추상적이며 성공을 증명하지 못함❓ MicroService 여러 개의 작은 서비스 집합으로 개발하는 접근 방법 서비스는 비즈니스 단위로 구분되어 별개의 인스턴스로 작동 여러 서비스가 모여 하나의 비즈니스 애플리케이션 구성 Polyglot 방식으로 서로 다른 언어와 DB 사용 가능 서비스는 서로 내부 API를 호출하여 통신 독립적인 확장 및 배포 가능📍 MicroService 단점 각 서비스가 독립적이기 때문에 통신을 위한 수많은 내부 service call 발생 Transaction 관리 난이도 상승 데이터 무결성 보장 난이도 상승 시스템 복잡도 상승❓ MSA MicroService Architecture 마이크로서비스 기반으로 시스템을 개발하는 아키텍처 및 개발 방식💡 MicroService 조건1. 업무 조직 성격의 변화 역할별 팀 구성 ➡ 목적별 팀 구성 팀마다 관리하는 서비스는 느슨한 연결로 구성2. 관리체계의 변화 목적팀 별 서비스 목표에 따라 방법론, 도구를 취사 선택3. 개발 생명 주기의 변화: 프로젝트 ➡ 제품 중식 Waterfall ➡ Agile 하나의 서비스를 개발하고 변경, 폐기하는 과정 용이4.개발 환경의 변화: 인프라 자동화 인프라 자동화는 개발 환경, 개발지원 환경을 자동화 하는 것을 의미 클라우드 인프라를 활용하여 쉽고 빠르게 개발 환경 구축 Infrastructure as Code를 통해 인프라 구성 및 애플리케이션 빌드 및 배포 등의 자동화를 코드로 처리5. 저장소의 변화: 통합 저장소 ➡ 분권 데이터 관리 서비스별 데이터베이스 사용 다른 서비스의 저장소를 직접 호출할 수 없고 오로지 API를 통해서 접근6. 실패를 고려한 설계 다양한 실패에 대비한 완벽한 테스트 환경 마련 시스템 실패를 감지하고 대응하기 위해 실시간 모니터링 체계 구축 Circuit breaker 패턴으로 긴급 장애 상황에 빠르고 유연하고 탄력적으로 대응🧐 Circuit breaker 각 서비스를 모니터링하고 있다가 한 서비스에서 장애가 발생하면 이를 호출하는 서비스의 연계를 차단하고 적절하게 대응하는 것을 의미📚 MSA 설계 원칙단일 책임 원칙 명확한 모듈 경계 설정 필요MicroService는 자율적 독립적 배포 독립적 실행 독립적 확장, 축소📍 MSA 설계 시 고려사항 서비스 간 호출량 내부 service call에 동기적 의존 관계 존재 여부 서비스 간 순환 의존 관계 존재 여부 Transaction 범위 하나의 service의 배포 크기 분리 시 유의미한 resource 사용량이 발생하는 기능📋 MSA 구성 요소API Gateway pattern 여러 MS App에서 공통적으로 필요한 기능 분리 e.g. 사용자 정보, 인증, 로깅 등 Routing 기능 수행RESTful 통신 인터페이스🎨 HATEOAS Hypermedia As The Engine Of Application State REST API를 통해 클라이언트가 서버와 동적인 상호작용하기 위한 매커니즘 REST API의 단점을 보완하기 위해 HATEOAS 사용 단점 1. 엔드 포인트 URL을 변경하면 모든 클라이언트의 URL 변경 단점 2. 자원의 상태를 고려하지 않기 때문에 클라이언트에서 처리 필요 링크에 사용 가능한 URL을 리소스로 전달하여 클라이언트가 참고하도록 하여 극복HAL Hypertext Application Language API의 리소스들 사이에 쉽고 일관적인 하이퍼링크를 제공하는 방식 응답에 참조 가능한 정보들을 요청 메시지에 포함 Context type은 application/hal+json{ \"_links\": { \"self\": {\"href\": \"/user/login\"} }}📍 MSA Monitoring 문제 분산된 각각의 서비스의 Health check 문제 클라우드 환경에서 로그 보관의 어려움 컨테이너의 짧은 수명 각 서비스 별로 분산되어 있는 로그 중앙 집중형 Monitoring Service 구축 필요- 서비스의 모든 로그 메시지 수집- 트랜잭션 연결 추적 가능- 로그 장기 보관 가능💊 장애 대응1. 장애 전파 차단 Circuit breaker로 장애 서비스 격리 Fallback으로 장애 서비스 대체2. 분산 저장 / 운영 Public Cloud를 사용하는 경우 다중 리전 사용3. Canary 배포 조금씩 사용자의 범위 확장 일부 트래픽을 새 버전의 서버로 분산하여 오류 여부 판단 빠르게 장애 감지 가능 장애를 감지하면 Rollback4. 장애 시나리오 Chaos Engineering🧶 Anti PatternMicroliths Monoliths 분해 실패 분해된 서비스끼리 강한 의존성Death Star 밀접하게 결합하고 뒤섞인 마이크로서비스🧵 보완 설계 패턴Service Mesh MicroService가 서로 데이터를 공유하는 방식을 제어하는 방법 가벼운 프록시를 Sidecar 패턴으로 배치 Sidecar는 모니터링, 로깅, 프록시 등의 동작 수행Istio Service Mesh 구현체 kubernetes 지원 MS contaier에 sidecar를 붙여서 배포 Logging, security, routing, discovery 등 cliend-side 역할 담당 각 MS는 서로 proxy를 통해 통신Serverless Computing Cold Start 이슈출처 Martin Fowler" }, { "title": "Domain Driven", "url": "/posts/Domain-Driven-Development/", "categories": "MSA", "tags": "msa, ddd", "date": "2022-04-18 23:00:00 +0900", "snippet": "🍃 기존의 개발 관계형 데이터 모델에 종속 최초 설계 데이터의 모델링의 변경과 확장하기 어려움 모델링과 실제 개발의 불일치 누적🎨 Domain Driven Design 데이터를 기능과 분리해서 식별하지 않고, 별도의 도메인 모델로 정의 용어 사전을 기반으로 도메인 설계 도메인 별로 설계와 구현 가능🧐 용어 사전 (Ubiquitous Language) 사용자와 설계자, 구현자가 모두 의미에 동의할 수 있는 용어의 모음✨ Domain 소프트웨어로 해결하고자 하는 문제 영역 개발하려는 서비스의 비즈니스 로직과 연관❓ Domain model 요구사항으로부터 Domain과 이하 entity를 정의하고 그 관계를 경계와 함께 추상화한 모식도📊 Domain-driven and Object-oriented ComperisonObject 추상화하거나 구체화할 수 있는 대상 e.g. 상품, 주문, 쿠폰Domain 요구사항에서 표현하는 모든 것 e.g. Object + 주문하다, 결제하다, 정산하다 등📌 Domain Driven Design Step 요구사항 정리 핵심 도메인 로직 파악 용어 사전 정리 도메인을 작은 단위로 분리 Bounded context 설정하고 관계 정의 세부 동작 설계 Context 별 bounds 침범 여부 확인 변경 사항 발생 시 반복📋 Domain Driven Design 기본 요소Domain model pattern Entity Value Object Service Aggregate RepositoryBounded Context 서로 독립적인 업무로 분할될 수 있는 모델 영역 MSA를 나누느 단위로 사용 가능🎄 Domain Driven ArchitectureClient Presentation layer에 HTTP Request 전달Presentation layer Client의 요청을 받고 Application layer로 전달받은 결과를 client에게 전달Application layer Client에게 제공할 결과를 Domain layer에 요청하여 조합Domain layer Domain model을 구현 하나의 대표되는 도메인이 다른 도메인의 처리 결과를 조합하는 경우가 많다고 한다.Infrastructure layer DB, 외부 시스템 등 연동 처리" }, { "title": "WebFlux", "url": "/posts/WebFlux/", "categories": "MSA", "tags": "msa, webflux, spring", "date": "2022-04-15 23:00:00 +0900", "snippet": "❓ WebFlux Client와 Server에서 reactive 스타일의 어플리케이션 개발을 도와주는 모듈 Spring5에서 reactive stack을 지원하는 web container framework🔎 WebFlux 특징 Non-Blocking IO 최소한의 리소스로 효율적인 운영 Singler worker thread가 event loop 처리 Event loop는 코어 개수만큼 존재 Functional Endpoints Lambda 기반 functional programming model Request router가 handler로 request routing Handler method에 @RequestMapping 선언부 없이 request, response를 app에서 전부 제어📊 Spring MVC and WebFlux Comparisonhttps://docs.spring.io MVC 요청 당 스레드를 따로 할당받아 blocking 처리 요청이 많을 수록 스레드 간 context switching 비용 증가 서버의 하드웨어 성능에 따라 원활한 서버 운영 가능 WebFlux Event loop model로 요청을 Non blocking 처리 적은 스레드에서 여러 작업 처리 스레드 간 context switching 비용 감소 요청이 적을 때 굳이 WebFlux를 사용하지 않아도 🙄..📋 WebFlux 프로젝트 구성 Filter Handler WebClient WebFluxConfigurer🎈 Handler HttpHandler Annotated Controller (기존의 MVC와 동일한 형식) Annotations를 통해 선언하며 콜백 받는다. WebHandler Functional Endpoint 처음부터 끝까지 요청 처리를 담당 및 제어 DispatcherHandler가 각 컴포넌트 호출🎠 Router Routing Function Handler Function에 요청들을 routing 해주는 역할 @RequestMapping 역할과 유사 @RequestMapping은 data만 전달 Router Function은 Mono&lt;Handler Function&gt;로 함수 전달 🔊 Filter WebHandler API에 적용 요청 처리 전에 선행 로직 실행 가능 API Gatway 역할을 하는 app에서 자주 사용📱 WebClient Non-blocking Http Client Module HTTP Request를 수행하는 client📝 R2DBC JDBC의 Blocking API를 대체하는 Nonblocking API Stack Spring 5.3.2+ JDBC를 사용한다면, blocking code가 격리되도록 하는 것이 중요📍 Handling Errors WebExceptionHandler WebFilter / WebHandler chain에서 발생한 Exception 처리" }, { "title": "Reactor Operations", "url": "/posts/Reactor-Operations/", "categories": "MSA", "tags": "msa, spring, reactor, reactive", "date": "2022-04-13 23:00:00 +0900", "snippet": "🧶 생성 Create https://reactivex.io/ Observable 생성 Just https://reactivex.io/documentation/operators/just.html 하나의 item만 방출(emit)하는 observable 생성 From https://reactivex.io/documentation/operators/from.html 다양한 객체와 데이터 유형을 observable로 변환 e.g. 리스트를 Flux로 변환 Empty https://reactivex.io/documentation/operators/empty-never-throw.html 빈 observable 생성 Defer https://reactivex.io/documentation/operators/defer.html observer가 구독할 때까지 observable을 생성하지 않고, 각 observer에 대해 새로운 observable 생성🔮 변환 flatMap https://reactivex.io/ 비동기 처리 groupBy https://reactivex.io/ Obsevable을 기준에 따라 그룹으로 obsevable 방출 map https://reactivex.io/ 동기 처리 입력과 리턴 값은 Mono&lt;T&gt;🔊 필터 distinct 중복을 없앤 observable 반환 filter 조건에 만족하는 항목만 방출 elementAt https://reactivex.io/ Flux에서 i번째 요소를 Mono로 반환 ignoreElements https://reactivex.io/ Observable의 항목을 내보내지 않고 종료 알림 발생 Observable을 사용하지 않고 종료할 때 이용 onNext 핸들러가 호출되지 않는다. take https://reactivex.io/ 앞에서 n개의 요소 방출🧩 결합 merge https://reactivex.io/ 여러 observable을 합쳐서 하나의 observable 반환 startWith https://reactivex.io/ Observable의 항목을 방출하기 전에 지정된 항목을 추가 zip https://reactivex.io/ 여러 observable의 방출을 결합하여 하나의 observable로 방출📍 오류 처리 onErrorResume https://reactivex.io/ error 신호 처리 try-catch 문에서 catch와 유사 retry https://reactivex.io/ error 신호가 발생하면 다시 실행🎮 유틸리티 delay Observable에서 방출 시점을 특정 시간만큼 앞으로 이동 do https://reactivex.io/ 원본 시퀀스에 영향을 주지 않고 처리 로직 추가 주로 시퀀스의 신호를 잡아서 사용 e.g. doOnNext, doOnComplete, doOnError 등 serialize https://reactivex.io/ Observable이 직렬화된 호출을 수행하고 올바르게 작동하도록 강제 subscribe Observable 방출 및 알림에 따라 작동 e.g. onNext, onError, onComplete 구독하지 않은 Observable은 처리되지 않는다. timestamp https://reactivex.io/ 각 항목에 타임스탬프 추가🔎 조건 all https://reactivex.io/ Observable이 내보낸 모든 항목이 조건을 만족하는지 여부 반환 contains https://reactivex.io/ Observable이 특정 항목을 방출하는지 여부 반환 defaultIfEmpty https://reactivex.io/ Observable이 아무것도 방출하지 않을 때 특정 항목 반환 skipWhile https://reactivex.io/ 조건을 만족하지 않을 때까지 방출된 항목 무시 takeWhile https://reactivex.io/ 조건을 만족하지 않은 후 observable이 내보낸 항목 무시📝 집계 average 뒤에 자료형을 붙여서 사용 평균을 Mono로 반환 count 조건을 만족하는 item의 개수를 카운팅하여 Mono로 반환 max 최댓값 min 최솟값 sum 합 reduce https://reactivex.io/ 시퀀스의 각 item에 함수를 순차적으로 적용하고 최종 값 반환" }, { "title": "Reactive Programming", "url": "/posts/Reactive-Programming/", "categories": "MSA", "tags": "msa, spring", "date": "2022-04-12 23:00:00 +0900", "snippet": "❓ Reactive System 응답이 잘 되고, 탄력적이며 유연하고 메시지 기반으로 동작하는 시스템📜 리액티브 선언문 유연하고, 느슨한 결합을 가지며, 확장성이 있다. 이로 인해 개발 및 변경 사항을 적용하기 쉽다. 장애가 발생하더라도, 간단한 방식으로 해결한다. 높은 응답성을 가지며, 사용자에게 효과적인 상호적 피드백을 제공한다.🔎 Reactive System 특징 Responsive (응답성) 요청에 대해 시스템은 가능한 즉각적으로 응답해야 한다. Resilient (탄력성) 장애가 발생하더라도 응답성을 유지한다. Elastic (유연성) 사용량의 변화에 대해 유연하게 대응한다. Message Driven (메시지 구동) 탄력성을 유지하기 위해 비동기 메시지 전달에 의존하여 구성 요소 사이에서 경계 형성❓ Reactive Programming 데이터의 흐름과 변화의 전파에 중점을 둔 프로그래밍 패러다임 기존의 명령형 프로그래밍은 작성한 코드의 순서대로 진행된다. 리액티브 프로그래밍은 데이터의 흐름을 정의하면 데이터의변화 혹은 작업의 종료에 따라 반응하여 진행된다. 데이터 흐름을 따라 하위 로직에 자동으로 변화를 전파할 수 있어야 한다.📋 Reactive Programming 주요 요소https://reactivex.io/ Observable 데이터 스트림 데이터 압축, 방출하는 역할 Observers Observable을 구독하고 방출된 데이터 스트림을 받아서 처리하는 역할 Schedulers 비동기 프로그래밍을 위한 요소 Observable과 Observers에게 실행되어야 할 스레드를 알려주는 역할📊 Marble Diagramhttps://reactivex.io/ Reactive Programming을 통해 발생하는 비동기적인 데이터 흐름을 시간에 따라 시각화한 다이어그램❓ Reactive Stream Nonblocking Backrpessure를 이용한 비동기 스트림 처리의 표준🧐 BackPressure 기존 옵저버 패턴은 Push 방식으로, Publisher가 데이터가 변경될 때마다 데이터 생성 BackPressure은 Pull 방식으로, Subscriber가 필요한 만큼만 요청📱 Reactive Stream을 구성하는 인터페이스 Processor 오퍼레이터 모음 Publisher 데이터를 생성하는 역할 Subscriber 데이터를 구독하고 처리하는 역할 Subscription Subscriber와 Publisher 사이의 데이터가 교환될 수 있도록 연결하는 역할 전달 받을 데이터의 개수를 요청하거나, 구독을 해지 할 수 있다.❓ Reactor 스프링 리액티브 개발에 사용되는 Reactive Stream의 구현체 중 하나🎁 Publisher의 구현체 Flux https://projectreactor.io/docs/core/release/reference/#flux 비동기 sequence 0 ~ N개의 아이템을 가진다. Mono https://projectreactor.io/docs/core/release/reference/#mono 비동기 item 0 또는 1개의 아이템을 가진다.🍃 Sequence 변화 가능한 데이터의 흐름 Publisher에 의해 publish 되고 Subscriber에 의해 subscription👮 Schedulers 오퍼레이터를 처리할 스레드를 지정한다. Reactor는 비동기 실행을 강제하지 않기 때문에 스케줄러를 사용하여 스레드를 지정한다. 스케줄러를 설정하지 않으면, 메인 스레드에서 동기적으로 실행 publishOn() 신호 처리 스케줄링 next, complete, error 신호 처리 스레드 설정 다음 publishOn을 만날 때까지 같은 스레드에서 동작 subscribeOn() 구독 처리 스케줄링 시퀀스를 실행할 스레드 결정 publishOn을 만날 때까지 같은 스레드에서 동작 publishOn이 신호를 처리할 스레드를 지정하므로, publishOn 뒤에 오는 subscribeOn은 무시된다.📊 publishOn() and subscribeOn() Comparison 공통점 스케줄러를 통해 스레드를 분리한다 차이점 publishOn 메서드는 신호, subscribeOn 메서드는 시퀀스를 처리할 스레드 지정publishOn 메서드가 subscribeOn 메서드보다 우선 순위가 높다.📒 Schedulers 종류 Immediate 지금 실행 중인 스레드에서 실행 Single 단일 스레드를 생성해 계속 재사용 Parallel Core 개수만큼의 스레드 생성 주로 CPU를 많이 사용하지만 생명주기가 짧은 작업 실행 매번 새로운 스레드를 사용한다. Elastic 스레드 무한정 생성 @Deprecated BoundedElastic Default로 Core * 10 만큼의 스레드 생성 우선적으로 스레드 풀에서 놀고 있는 스레드를 사용하고, 없으면 새로 만들어 사용한다.✨ Reactive Programming 장점1. 장애가 전파되지 않는다. 장애가 발생한 처리자는 구독한 데이터를 처리할 수 없다. 시퀀스에서 처리되지 않은 데이터는 그대로 흘러간다.2. 비동기 처리 스케줄러를 이용하여 스레드를 쉽게 사용할 수 있다.3. 리소스의 효율적인 사용 요청자는 처리자가 작업을 완료하기 전까지 다른 작업을 하거나 리소스를 반납한다. 스레드를 점유하지 않는다." }, { "title": "Even Driven", "url": "/posts/Even-Driven/", "categories": "MSA", "tags": "msa", "date": "2022-04-12 05:00:00 +0900", "snippet": "❓ Event Driven Architecture 이벤트 기반의 아키텍처 설계 방식 비동기 통신 방식을 이용해 느슨한 결합을 지향하는 아키텍처 MSA 시스템에서 producer가 이벤트를 publish하고, 이벤트를 구독하고 있던 consumer가 이벤트를 받아 처리하는 시스템 📋 Event Driven 주요 요소1. Event 프로그램에 의해 감지되고 처리될 수 있는 동작이나 사건관찰의 대상이 되는 사건 정보를 담고 있다.{ \"id\": \"해싱된 키\", \"message\": \"처리할 사건\", \"createdAt\": \"timestamp\"}2. Producer 이벤트 감지와 생성3. Consumer 이벤트를 구독하고, 관심있는 이벤트가 발생하면 처리4. Event Bus Producer에서 Consumer로 이벤트 전달🔒 Event Driven 제약 사항 이벤트는 발생한 사건에 대해 약속된 형식 사용 불변 (과거의 메시지를 변경할 수 없다.) 발생한 사건에 대한 결과 상태 전달 생성자는 이벤트 처리 상태에 관여하지 않는다. 소비자는 이벤트 생성자에 관심 갖지 않는다.🔎 Event Driven Architecture 동작 방식1. Message 생성 (Publish/Subscribe) 이벤트가 생성되면 Subcriber에게 전달된다. 반복되어 전달되지 않으며, 수신자는 송신자의 정보를 알 필요가 없다.2. Event Source Event Processor에게 이벤트를 전달하는 역할 Event Source는 1개 이상일 수 있고, 1개 이상의 Event Processor에게 전달한다.3. Event Processor 수신된 이벤트에 대한 여러 행동을 수행하는 역할4. Event Consumer 이벤트를 처리하는 역할🧐 Event Driven Architecture 설계 시 고려 사항1. Loosely coupling 2. Removing dependencies 시스템 간 의존성은 감소하나, Message Broker에 대한 의존성 발생3. Nonblocking transaction 트랜잭션 간에 영향을 주지 않도록 설계해야 한다.4. Asynchronized callback 5. Fallback / Retry 작업을 실패한 경우, 이전 작업까지 fallback을 하고 Retry할 수 있도록 설계해야 한다.6. Event logging 🎨 Event Driven Architecture Pattern1. Single Producer - Single Consumer 가장 단순한 형태2. Single Producer - Multi Consumer 이벤트 처리 비용이 이벤트 생성 비용보다 높을 경우3. Dead Letter Queue 이벤트를 처리하는 데 실패했을 때 어떻게 할 것인가? Retry로 이벤트를 다시 큐로 이동시켜 재처리 설정한 Retry limitation 동안 이벤트 처리되지 않을 경우 main queue에서 제거하고 사후 분석을 위해 DLQ로 이동4. Time To Live 처리되지 않은 이벤트의 생명 주기를 제한하여 만료되면 이벤트 폐기5. Asynchronous request-response Polling6. Event splitting 한 Event에 대해 여러 로직의 처리가 필요할 경우 사용 단일 책임의 원칙을 벗어나는 경우 이벤트를 나눠서 처리한다.✨ Event Driven Architecture 특장점1. Service 간 호출이 많은 MSA에 적합 비동기적으로 다수의 컨슈머가 이벤트 버스를 통해 다수의 이벤트를 처리하는 형식 Service간 호출이 많은 MicroService Architecture에 적합하다.2. Infra Structure의 유연한 사용 하드웨어 인프라에서는 불가능3. Polyglot 모듈별로 여러 언어를 사용하여 구사하는 것이 가능하다.4. 가용성, 응답성 개선 효율성과 성능의 향상 기대5. Fault Isolation 하나의 서버에 장애가 발생하더라도, 시스템 전체에 영향을 미치지 않는다. 단, 서버의 장애가 지속되면 시스템 전체에도 영향을 미친다.📍 Event Driven Architecture 단점1. 설계 복잡도 증가 2. Message Broker 의존성 증가 Message Broker를 보호하는 아키텍처를 만든다.3. 코드 가독성 하락 4. 디버깅 난이도 상승 5. log를 통한 system flow 가독성 하락 💻 Event Driven Programming 이벤트 발생에 의해 프로그램 흐름이 결정되는 프로그래밍 패러다임🔎 Even Driven Programming 특징 Consumer ↔ Producer는 Broker 통해 소통 Message 생성 후 소비 전까지 Queue에 저장 ✨ Consumer ↔ Producer의 분리로 인한 이점 N개의 consumer, producer 동시 처리 실패한 작업 재시도 및 logging 로직 단순화 Consumer Scale out으로 컴퓨팅 리소스 확장" }, { "title": "Async-Nonblocking", "url": "/posts/Async-Nonblocking/", "categories": "MSA", "tags": "msa", "date": "2022-04-11 06:00:00 +0900", "snippet": "📚 Synchronous특정 함수를 호출한 뒤 해당 함수의 리턴 값을 확인하며 응답을 받기 전까지 동작을 멈춘다.📚 Asynchronous요청을 보낸 후 응답과는 상관없이 다음 동작을 실행한다.📊 Sync&amp;Async Comparison 요청자와 처리자가 서로의 시간을 공유하는지 여부에 따라 동기, 비동기로 구분된다.📚 Non-Blocking함수 A가 함수 B를 호출해도 함수 A가 제어권을 가진다. 제어권 : 함수 자신의 코드를 실행할 권리를 의미📊 Blocking and Non-Blocking Comparison" }, { "title": "[BOJ] 위상 정렬 🥇3", "url": "/posts/BOJ-9470/", "categories": "Algorithm", "tags": "algorithm, boj", "date": "2022-03-21 06:00:00 +0900", "snippet": "📚 Topological Sort 출처 : https://www.acmicpc.net/problem/9470💡 풀이import sysfrom collections import dequeinput = sys.stdin.readlineT = int(input())for _ in range(T): k, m, p = map(int, input().split()) # 테스트 케이스 번호, 노드 개수, 간선 수 graph = [[] for _ in range(m + 1)] inDegree = [0] * (m + 1) # 진입차수 dp = [[0] * (m + 1) for _ in range(m + 1)] end = 0 # 마지막 노드 번호 for _ in range(p): # 그래프와 진입 차수 설정 a, b = map(int, input().split()) graph[a].append(b) inDegree[b] += 1 queue = deque() for i in range(1, m + 1): # 진입 차수가 0인 노드를 queue에 추가 if inDegree[i] == 0: queue.append(i) dp[i][i] = 1 while queue: x = queue.popleft() end = x for i in graph[x]: inDegree[i] -= 1 dp[x][i] = dp[x][x] if inDegree[i] == 0: queue.append(i) max_ = 0 count = 0 for row in range(1, m + 1): if max_ != 0 and dp[row][i] == max_: # 가장 큰 강의 개수 카운팅 count += 1 elif dp[row][i] &gt; max_: # 가장 큰 강의 개수 찾기 max_ = dp[row][i] count = 1 dp[i][i] = max_ if count == 1 else max_ + 1 print(k, dp[end][end])print(*result)📝 해설1. 아래와 같은 2차원 리스트(이하 dp)가 있다고 가정한다.2. 진입 차수가 0인 노드의 번호를 i라고 가정하면, dp[i][i]에 1로 설정한다.3. 노드 a에서 노드 b로 가는 경로가 있다면, 진입 차수를 감소시키고 dp[a][b]의 값을 dp[a][a] 값으로 변환한다.4. 진입 차수가 0이 되었다면, queue에 노드 번호를 넣고, 아래의 조건에 따라 dp 테이블의 값을 갱신한다. 노드 번호 v에서 해당 노드로 들어오는 강의 순서 중 가장 큰 값을 i라고 하였을 때 해당 노드로 들어오는 모든 강 중에서 강의 순서가 i인 강이 1개이면, dp[v][v]의 값을 i로 설정한다. i인 강이 2개 이상이면 dp[v][v]의 값을 i + 1로 설정한다.5. 과정 3 ~ 4를 반복하면 아래와 같은 dp 테이블이 만들어진다.6. 마지막 노드를 v라고 한다면, 하천계의 Strahler 순서는 dp[v][v]가 된다.💣 고려하지 않아도 되는 사항dp[x][i] = dp[x][x] queue.popleft()를 통해 나온 노드 번호가 v라고 했을 때, dp[v][v] 값은 항상 존재한다.dp[i][i] = max_ if count == 1 else max_ + 1 시작 지점이 아닌 모든 노드에는 진입 간선이 존재하므로 변수 max_는 최소 1의 값을 가지게 된다. dp[i][i]는 시작 지점이 아니기 때문에, 가장 큰 강의 개수 i가 1개인지, 2개 이상인지만을 고려하면 된다." }, { "title": "[BOJ] 위상 정렬 Basic", "url": "/posts/BOJ-2252/", "categories": "Algorithm", "tags": "algorithm, boj", "date": "2022-03-17 06:00:00 +0900", "snippet": "📚 Topological Sort 출처 : https://www.acmicpc.net/problem/2252❓ 위상 정렬 순서가 정해져 있는 작업을 수행해야 할 때 그 순서를 결정하기 위해 사용하는 알고리즘 사이클이 없는 방향 그래프의 모든 노드를 순서대로 나열한 것🧐 Directed Acyclic Graph (DAG) 사이클이 없는 방향 그래프로, DAG는 이벤트 간의 우선순위를 나타내기 위해 주로 사용한다.💡 풀이import sysfrom collections import dequeinput = sys.stdin.readlinen, m = map(int, input().split())inDegree = [0] * (n + 1)graph = [[] for _ in range(n + 1)]result = []for _ in range(m): a, b = map(int, input().split()) inDegree[b] += 1 graph[a].append(b)queue = deque()for i in range(1, n + 1): if inDegree[i] == 0: queue.append(i)while queue: x = queue.popleft() result.append(x) for i in graph[x]: inDegree[i] -= 1 if inDegree[i] == 0: queue.append(i) print(*result)📝 해설각 노드의 진입 차수를 구한다. 각 노드의 진입 차수는 해당 노드로 들어오는 간선의 수 를 의미한다. e.g. a -&gt; b 간선이 존재하면 리스트 inDegree의 b 요소의 값을 증가시킨다.진입 차수가 0인 노드를 덱에 삽입한다. BFS 알고리즘을 사용하여 순서대로 탐색하기 위해 시작점을 정하는 과정이라고 생각하면 된다.아래의 과정을 통해 덱에서 나오는 순서대로 노드들이 정렬된다.1. 덱의 왼쪽에 있는 노드를 순서대로 꺼낸다.2. 덱에서 꺼낸 노드에서 다른 노드로 향하는 간선이 있다면, 다른 노드의 진입 차수를 감소시킨다.3. 다른 노드의 진입 차수가 0이 되었다면, 덱에 삽입한다.4. 위의 과정을 반복한다." }, { "title": "[BOJ] 최장 공통 부분 수열", "url": "/posts/BOJ-9251/", "categories": "Algorithm", "tags": "algorithm, boj", "date": "2022-03-09 06:00:00 +0900", "snippet": "📚 Longest Common Subsequence 출처 : https://www.acmicpc.net/problem/9251❓ 최장 공통 부분 수열두 문자열이 주어졌을 때, 부분 문자열 중 가장 긴 것을 찾는 문제💡 풀이str1 = input()str2 = input()n, m = len(str1), len(str2)dp = [[0] * (m + 1) for _ in range(n + 1)]for i in range(1, n + 1): for j in range(1, m + 1): if str1[i - 1] == str2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])print(dp[n][m])📝 해설1. 아래와 같은 2차원 리스트(이하 dp)가 있다고 가정한다.2. 첫 번째 문자열 j-1번째 문자와 두 번째 문자열 j-1번째 문자가 다르다면, dp[i - 1][j]와 dp[i][j - 1] 중 큰 값을 대입한다.3. 만약 두 문자가 같다면, dp[i - 1][j - 1] + 1 값을 대입한다.4. 위의 과정을 반복하면 아래와 같은 리스트가 완성되고, 정답은 가장 마지막 요소가 된다." }, { "title": "Stack", "url": "/posts/Python-Stack/", "categories": "Learn, Python", "tags": "data structure, python, learn", "date": "2022-02-27 06:00:00 +0900", "snippet": "📚 Stack 구현 기능 Event Description push(data) 맨 앞에 데이터 넣기 pop() 맨 앞의 데이터 뽑기 peek() 맨 앞의 데이터 보기 isEmpty() 스택의 사용 여부 반환 LIFO 구현 class Node: def __init__(self, data): self.data = data self.next = Noneclass Stack: def __init__(self): self.head = None def push(self, item): new_head = Node(item) new_head.next = self.head self.head = new_head def pop(self): if self.isEmpty(): return \"Stack is Empty\" item = self.head self.head = self.head.next return item def peek(self): if self.isEmpty(): return \"Stack is Empty\" return self.head.data def isEmpty(self): return self.head is None" }, { "title": "Queue", "url": "/posts/Python-Queue/", "categories": "Learn, Python", "tags": "data structure, python, learn", "date": "2022-02-27 06:00:00 +0900", "snippet": "📚 Queue 구현 기능 Event Description enqueue(data) 맨 뒤에 데이터 추가하기 dequeue() 맨 앞의 데이터 뽑기 peek() 맨 앞의 데이터 보기 isEmpty() 큐의 사용 여부 반환 FIFO 구현 class Node: def __init__(self, data): self.data = data self.next = Noneclass Queue: def __init__(self): self.head = None self.tail = None def enqueue(self, data): new_node = Node(data) if self.isEmpty(): self.head = new_node self.tail = new_node return self.tail.next = new_node self.tail = new_node def dequeue(self): if self.isEmpty(): return \"Queue is Empty\" node = self.head self.head = self.head.next return node.data def peek(self): if self.isEmpty(): return \"Queue is Empty\" return self.head.data def isEmpty(self): return self.head is None" }, { "title": "LinkedList", "url": "/posts/Python-LinkedList/", "categories": "Learn, Python", "tags": "data structure, python, learn", "date": "2022-02-27 06:00:00 +0900", "snippet": "📚 Array와 LinkedList 차이점 Event Array LinkedList 특정 원소 조회 O(1) O(N) 중간에 원소 삽입 / 삭제 O(N) O(1) 정리 데이터 접근이 빈번한 경우 사용 데이터 변경이 빈번한 경우 사용 Array는 인덱스로 접근이 가능하기 때문에 조회할 때 상수 시간 소요📚 LinkedList 구현class Node: def __init__(self, data): self.data = data self.next = Noneclass LinkedList: def __init__(self, value): self.head = Node(value) self.next = None def append(self, value): cur = self.head while cur.next is not None: cur = cur.next cur.next = Node(value) def all_print(self): cur = self.head while cur is not None: print(cur.data) cur = cur.next def get_node(self, index): node = self.head for i in range(1, index): node = node.next return node def add_node(self, index, value): new_node = Node(value) if index == 0: new_node.next = self.head self.head = new_node return node = self.get_node(index - 1) next_node = node.next node.next = new_node new_node.next = next_node def delete_node(self, index): if index == 0: self.head = self.head.next return node = self.get_node(index - 1) node.next = node.next.next" }, { "title": "트리 자료구조", "url": "/posts/Python-Tree/", "categories": "Learn, Python", "tags": "data structure, python, learn", "date": "2022-02-25 06:00:00 +0900", "snippet": "📚 Tree계층적인 구조를 표현할 때 사용하는 자료구조 트리 관련 용어 명칭 의미 루트 노드 (root node) 부모가 없는 최상위 노드 단말 노드 (leaf node) 자식이 없는 노드 크기 (size) 트리에 포함된 모든 노드의 개수 깊이 (depth) 루트 노드부터의 거리 높이 (height) 깊이 중 최댓값 차수 (degree) 각 노드의 (자식 방향) 간선 개수 📚 트리의 순회 트리 자료구조에 포함된 노드를 특정한 방법으로 한 번씩 방문하는 방법 전위 순회 (Pre-order traverse)def preorderTraversal(node): print(node) if node.left: preorderTraversal(node.left) if node.right: preorederTraversal(node.right) 중위 순회 (In-order traverse)def inorderTraversal(node): if node.left: inorderTraversal(node.left) print(node) if node.right: inorderTraversal(node.right) 후위 순회 (Post-order traverse)def postorderTraversal(node): if node.left: postorderTraversal(node.left) if node.right: postorderTraversal(node.right) print(node)" }, { "title": "[BOJ] 최장 증가 부분 수열", "url": "/posts/BOJ-12015/", "categories": "Algorithm", "tags": "algorithm, boj", "date": "2022-02-21 06:00:00 +0900", "snippet": "📚 Longest Increasing Subsequence 출처 : https://www.acmicpc.net/problem/12015❓ 최장 증가 부분 수열어떤 임의의 수열에서 몇 개의 수들을 제거하면 부분수열을 만들 수 있다.부분수열 중 오름차순으로 정렬된 가장 긴 수열을 최장 증가 부분 수열 이라고 한다.💡 풀이from bisect import bisect_leftn = int(input())arr = list(map(int, input().split()))# 최장 증가 부분 수열을 저장할 리스트lis = []for a in arr: # 리스트 lis에서 a를 삽입할 가장 왼쪽 인덱스 찾기 idx = bisect_left(lis, a) # 인덱스 값이 리스트 lis 길이보다 크거나 같으면 a를 삽입 if len(lis) &lt;= idx: lis.append(a) else: lis[idx] = aprint(len(lis))📝 해설 bisect bisect 라이브러리는 정렬된 배열에서 특정 원소를 찾을 때 O(lonN) 으로 동작한다. lis[idx] = a 인덱스 값이 리스트 lis보다 작으면 해당 인덱스의 위치의 값을 갱신하면서 오름차순으로 정렬된 가장 긴 수열을 만든다." }, { "title": "Python 최대 공약수, 최소 공배수", "url": "/posts/Python-Study/", "categories": "Learn, Python", "tags": "python, learn", "date": "2022-02-10 06:00:00 +0900", "snippet": "📚 최대 공약수 유클리드 호제법 두 자연수 A, B에 대하여 (A &gt; B) A를 B로 나눈 나머지와 B의 최대 공약수는 A와 B의 최대 공약수와 같다. def gcd(a, b):if a % b == 0: return belse: return gcd(b, a % b) 📚 최소 공배수 구현 서로 다른 a, b의 곱을 a, b의 최대 공약수로 나눈다. def lcm(a, b):return a * b / gcd(a,b) 📚 math 라이브러리를 사용하여 구하기 import math# 최대 공약수print(math.gcd(6, 9))# 최소 공배수print(math.lcm(2, 3))" }, { "title": "Python 문법", "url": "/posts/Python-Grammar/", "categories": "Learn, Python", "tags": "python, learn", "date": "2022-02-08 06:00:00 +0900", "snippet": "📚 리스트 컴프리헨션 대괄호 안에 조건문과 반복문을 적용하여 리스트를 초기화하는 방법a = [i for i in range(5)] 리스트에서 특정 값을 가지는 원소를 모두 제거하기 arr = [1, 1, 2, 2, 3]search = {1, 2}# arr에 1, 2를 제외한 값만 저장res = [a for a in arr if a not in search] 리스트 관련 메서드의 시간 복잡도 함수명 시간 복잡도 append() O(1) sort() O(NlogN) reverse() O(N) insert() O(N) count() O(N) remove() O(N) 📚 튜플 특징 튜플은 한 번 선언된 값을 변경할 수 없다. 튜플은 리스트에 비해 상대적으로 공간 효율적이다. 튜플을 비롯하여 리스트는 순서가 존재한다. 튜플은 사용하면 좋은 경우 서로 다른 성질의 데이터를 묶어서 관리해야 하는 경우 메모리를 효율적으로 사용해야 하는 경우📚 집합 set() 중복을 허용하지 않는다. 순서가 존재하지 않는다. 사전 자료형과 집합 자료형은 순서가 없기 때문에 검색할 때 O(1)의 시간 복잡도를 가진다. 집합 자료형 연산 s1 = {1, 2, 3}s2 = {3, 4}# 합집합print(s1 | s2)print(s2.union(s1))# 교집합print(s1 &amp; s2)print(s1.intersection(s2))# 합집합print(s1 - s2)print(s1.difference(s2))📚 함수 eval() # 문자열 형태의 식을 계산해주는 함수print(eval(\"2+3\")) 만약, 피연산자 앞에 0이 붙어 있는 경우, 오류가 발생한다. (Ex. 1+01)📚 라이브러리 itertools # 순열 : 서로 다른 n개에서 서로 다른 r개를 선택하여 나열from itertools import permutations# 조합 : 서로 다른 n개에서 순서와 상관 없이 서로 다른 r개 선택from itertools import combinations# 중복 순열 : 중복 가능한 n개에서 r개를 선택하여 나열from itertools import product# 중복 조합 : 중복 가능한 n개에서 순서와 상관 없이 r개 선택from itertools import combinationswith_replacement collections # 카운팅from collections import Countera = ['apple', 'banana', 'apple']counter = Counter(a)# 업데이트counter.update(a)# 가장 빈도가 높은 순으로 n개 출력print(counter.most_common(n))# 큐 구현# 리스트를 사용하는 경우보다 효율성이 높다.from collections import dequequeue = deque()queue.append(1)queue.popleft()" }, { "title": "[프로그래머스] N-Queen", "url": "/posts/N-Queen/", "categories": "Algorithm", "tags": "algorithm, programmers", "date": "2021-12-05 06:00:00 +0900", "snippet": "📚 N-Queen 출처 : https://programmers.co.kr/learn/courses/30/lessons/12952❓ 풀이 방법사실 처음 보자마자 dfs로 풀어야 겠다고 생각하고 이중 for문에 deque를 쓰면서 풀었다.그 결과 테스트 케이스 2/3 정도 틀렸다 😆📍 내 풀이의 문제점퀸이 대각선에 있는 경우를 제대로 고려하지 못한 것으로 분석된다.💡 해결 방법 퀸은 가로, 세로, 대각선으로 이동할 수 있기 때문에 같은 행, 열, 대각선에 위치할 수 없다. column 차이와 row 차이가 같은지 확인 퀸의 위치를 2차원이 아닌 1차원 리스트로 관리" }, { "title": "Kotlin SpannableString", "url": "/posts/Kotlin-SpannableString/", "categories": "Learn, Kotlin", "tags": "kotlin, learn", "date": "2021-10-27 06:00:00 +0900", "snippet": "📚 Kotlin SpannableString❓ SpannableStringSpannableString class는 텍스트를 출력할 때 텍스트 일부의 색상, 크기, 스타일 등을 변경할 때 사용한다.위의 사진은 현재 진행하고 있는 프로젝트에 적용한 예시이다.TextView의 내용 중 오른쪽 디데이에 포인트를 주고 싶어서 SpannableString class를 사용하였다.📝 Process1. 아래와 같이 디데이를 변경해 줄 함수를 구현하였다.private fun setRange(date: String, day: String): SpannableString { val start = date.length val end = date.length + day.length val spannable = SpannableString(\"$date$day\") // 글자 색상 변경 spannable.setSpan(ForegroundColorSpan(getColor(R.color.blue)), start, end, Spannable.SPAN_EXCLUSIVE_EXCLUSIVE) // 글자 스타일 변경 spannable.setSpan(StyleSpan(Typeface.BOLD), start, end, Spannable.SPAN_EXCLUSIVE_EXCLUSIVE); // 글자 크기 변경 spannable.setSpan(RelativeSizeSpan(1.3f), start, end, SpannableString.SPAN_EXCLUSIVE_EXCLUSIVE);}2. 함수를 호출한다. (두 번째 매개변수에 해당하는 텍스트의 스타일을 변경할 것이다.)binding.tvRange.setText(setRange(strDate, \"+$day\"), TextView.BufferType.SPANNABLE)" }, { "title": "Kotlin Firebase", "url": "/posts/Kotlin-Firebase/", "categories": "Learn, Kotlin", "tags": "kotlin, learn", "date": "2021-10-27 06:00:00 +0900", "snippet": "📚 Kotlin Firebase프로젝트에서 Kotlin으로 Firebase를 연동하여 database에 데이터를 읽고 쓰는 작업을 하였다.Database에는 아두이노 보드에서 저장한 센서의 값과 앱에서 사용자가 등록한 데이터가 저장되어 있다.데이터베이스에 저장되어 있는 데이터를 kolin을 이용하여 읽고 쓰는 부분을 간략하게 가져왔다." }, { "title": "Installing Android Studio on Ubuntu 20.04", "url": "/posts/Installing-Android-Studio-on-Ubuntu/", "categories": "Learn, Kotlin", "tags": "ubuntu, android", "date": "2021-10-18 06:00:00 +0900", "snippet": "sudo apt-add-repository ppa:maarten-fonville/android-studiosudo apt-get updatesudo apt-get install android-studio" }, { "title": "SQLD 합격 후기", "url": "/posts/SQLD-pass-note/", "categories": "Daily", "tags": "sqld, daily", "date": "2021-10-03 06:00:00 +0900", "snippet": "💙 제42회 SQLD 시험에 합격했다. 시험은 9월 5일에 치러졌다.이틀 전에 COVID19 2차 예방 접종을 받고 부작용 때문에 시험장에 입실을 할 수 있을지 걱정했다.다행히 입실을 할 수 있었지만, 하루 전에 발열로 끙끙 앓고 당일에는 몸 상태가 좋지 못하여 좋은 결과를 기대하기 어려웠다. 😂핑계일 수 있고 높은 점수를 받은 것은 아니지만, 합격한 사실이 기뻐서 글을 남겨 본다 😊❓ Why ❓대학교 다니면서 데이터베이스 관련 강의를 듣고, 데이터베이스를 구축하는 프로젝트를 수행하면서 데이터베이스에 관심이 생겨서 응시하게 된 자격증이다.❓ How ❓방학 동안 인턴으로 근무하면서 자격증 공부를 하지 않아서 준비하기에는 빠듯하였다. 이것도 핑계.. 😂인턴 근무 종료 후 본가에서 요양하다가 비싼 응시료 때문에 마지 못해 인터넷에 돌아다니는 기본서를 보았다생각보다 공부할 양이 많아서 미리 준비하지 않은 것에 후회했지만, 아이패드 장만한 버프로 이틀 동안 아이패드 화면만 들여다보았다.역시 공부는 장비 빨 인가 😙" }, { "title": "Git 사용 방법", "url": "/posts/Git-Tutorial/", "categories": "Git", "tags": "git", "date": "2021-07-03 06:00:00 +0900", "snippet": "📚 Git 소스 코드의 버전 관리 프로그램 여러 개발자와의 협업 가능 GitHub, GitLab은 Git 기반의 저장소 서비스저장소의 프로젝트를 Local 저장소로 복제git clone &lt;url&gt;내 컴퓨터에서 디렉토리를 만들어 시작하는 경우cd ./디렉토리git init# 저장소의 내용을 가져온다git remote add &lt;저장소&gt; &lt;url&gt;git 저장소마다 다른 계정으로 설정 가능git config user.name \"name\"git config user.email \"@\"git commit log 확인git log git log 명령어를 통해 commit id 확인 가능전체 commit log 확인git log --all --graphHEAD가 가리켰던 커밋 기록을 모두 확인git reflog reference log 숫자가 낮을수록 최근기록git commit 내용 비교git diff &lt;commit_id&gt; &lt;commit_id&gt; commit id를 다 적지 않고 구분 가능한 정도만 적어주어도 된다.원하는 commit 시점으로 변경git reset --option &lt;commit_id&gt;📍 옵션 –hard : Working Directory 내용 변경 –mixed : Working Directory 변경하지 않고 Staging Area를 해당 커밋처럼 변경 –soft : Working Directory, Staging Area 변경하지 않고 HEAD가 가리키는 커밋만 변경git의 현재상태git statusgit branch 생성git branch &lt;branch_name&gt;git branch 변경git checkout &lt;branch_name&gt;HEAD가 가리키는 branch에 target_branch 병합git merge &lt;target_branch_name&gt; merge 과정에서 충돌이 발생한 경우, 충돌이 발생한 파일을 직접 수정하고 add와 commit 진행원격 저장소에 변경 사항 업로드git push -u origin master📍 옵션 -u 옵션 : –set-upstream : 내 컴퓨터의 master 브랜치가 저장소 서버의 master 브랜치를 가르키도록 -u 옵션을 사용할 경우 뒤에 저장소와 branch를 명시하지 않아도 된다. –force : 강제 업로드fork 원본 프로젝트와 동일한 복제 프로젝트 만들기 복제 프로젝트로 작업 후 원본 프로젝트로 merge request 보내기" } ]
